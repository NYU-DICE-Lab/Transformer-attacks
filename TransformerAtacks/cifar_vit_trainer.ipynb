{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torchvision\n",
    "from torchvision.transforms import ToTensor, Resize, Compose, Normalize\n",
    "from torchvision.datasets import CIFAR10\n",
    "from timm.models import create_model, apply_test_time_pool, load_checkpoint, is_model, list_models\n",
    "from timm.data import Dataset, DatasetTar, create_loader, resolve_data_config, RealLabelsImagenet\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.models import wide_resnet50_2 as wrn50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mSignature:\u001b[0m \u001b[0mwrn50\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpretrained\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprogress\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m\n",
       "Wide ResNet-50-2 model from\n",
       "`\"Wide Residual Networks\" <https://arxiv.org/pdf/1605.07146.pdf>`_\n",
       "\n",
       "The model is the same as ResNet except for the bottleneck number of channels\n",
       "which is twice larger in every block. The number of channels in outer 1x1\n",
       "convolutions is the same, e.g. last block in ResNet-50 has 2048-512-2048\n",
       "channels, and in Wide ResNet-50-2 has 2048-1024-2048.\n",
       "\n",
       "Args:\n",
       "    pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
       "    progress (bool): If True, displays a progress bar of the download to stderr\n",
       "\u001b[0;31mFile:\u001b[0m      ~/Projects/venv/lib/python3.8/site-packages/torchvision/models/resnet.py\n",
       "\u001b[0;31mType:\u001b[0m      function\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "?wrn50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = create_model('vit_base_patch16_384', pretrained=True)\n",
    "#model = create_model('tv_resnet101', pretrained=True)\n",
    "model = wrn50(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fc = nn.Linear(2048, 10, bias=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.reset_classifier(num_classes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "transforms = Compose([Resize(384), ToTensor(), Normalize(mean=(0.5,0.5, 0.5), std=(0.5, 0.5, 0.5))])\n",
    "cifar10 = CIFAR10(root='./datasets/train/', download=True, train=True, transform=transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "cifar10_test = CIFAR10(root='./datasets/test/', download=True, train=False, transform=transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = DataLoader(cifar10, batch_size=16, drop_last=True)\n",
    "test_dl = DataLoader(cifar10_test, batch_size=16, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "optim = torch.optim.SGD(model.parameters(), lr=0.03, momentum=0.9, weight_decay=5e-4)\n",
    "#sched = torch.optim.lr_scheduler.ExponentialLR(optim, gamma=0.95)\n",
    "best_acc = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Idx:0, Train_loss:0.8777157068252563, Test loss:1.2062662839889526, test accuracy:0.58\n",
      "Idx:100, Train_loss:1.4707999229431152, Test loss:1.4834874868392944, test accuracy:0.55\n",
      "Idx:200, Train_loss:1.6017284393310547, Test loss:0.8672785758972168, test accuracy:0.58\n",
      "Idx:300, Train_loss:0.9733362793922424, Test loss:1.4643990993499756, test accuracy:0.57\n",
      "Idx:400, Train_loss:1.1839113235473633, Test loss:1.1384563446044922, test accuracy:0.60\n",
      "Idx:500, Train_loss:1.2378023862838745, Test loss:1.4023743867874146, test accuracy:0.55\n",
      "Idx:600, Train_loss:1.4214180707931519, Test loss:1.5212477445602417, test accuracy:0.56\n",
      "Idx:700, Train_loss:0.8655726909637451, Test loss:0.905354917049408, test accuracy:0.61\n",
      "Idx:800, Train_loss:1.1174672842025757, Test loss:1.3106553554534912, test accuracy:0.61\n",
      "Idx:900, Train_loss:1.0688982009887695, Test loss:1.202191948890686, test accuracy:0.61\n",
      "Idx:1000, Train_loss:1.5668672323226929, Test loss:1.2677035331726074, test accuracy:0.57\n",
      "Idx:1100, Train_loss:1.0509084463119507, Test loss:1.0046957731246948, test accuracy:0.56\n",
      "Idx:1200, Train_loss:1.1135636568069458, Test loss:1.3382182121276855, test accuracy:0.59\n",
      "Idx:1300, Train_loss:1.5640430450439453, Test loss:1.2233037948608398, test accuracy:0.61\n",
      "Idx:1400, Train_loss:1.2430870532989502, Test loss:1.6327546834945679, test accuracy:0.56\n",
      "Idx:1500, Train_loss:0.6383843421936035, Test loss:1.1594111919403076, test accuracy:0.60\n",
      "Idx:1600, Train_loss:1.2568272352218628, Test loss:1.0530580282211304, test accuracy:0.59\n",
      "saving model\n",
      "Idx:1700, Train_loss:1.565879464149475, Test loss:0.8795508742332458, test accuracy:0.62\n",
      "Idx:1800, Train_loss:0.5193407535552979, Test loss:1.493060827255249, test accuracy:0.59\n",
      "saving model\n",
      "Idx:1900, Train_loss:1.2358450889587402, Test loss:0.8648863434791565, test accuracy:0.63\n",
      "Idx:2000, Train_loss:1.0351473093032837, Test loss:1.0917834043502808, test accuracy:0.60\n",
      "Idx:2100, Train_loss:1.4392890930175781, Test loss:1.10761296749115, test accuracy:0.60\n",
      "Idx:2200, Train_loss:0.9580432772636414, Test loss:1.1430178880691528, test accuracy:0.59\n",
      "Idx:2300, Train_loss:0.9967526793479919, Test loss:1.5091253519058228, test accuracy:0.58\n",
      "Idx:2400, Train_loss:0.7443051338195801, Test loss:1.1149754524230957, test accuracy:0.60\n",
      "Idx:2500, Train_loss:0.9760429263114929, Test loss:1.5531117916107178, test accuracy:0.60\n",
      "Idx:2600, Train_loss:0.969810962677002, Test loss:1.1589765548706055, test accuracy:0.63\n",
      "saving model\n",
      "Idx:2700, Train_loss:0.9101470708847046, Test loss:1.0258150100708008, test accuracy:0.65\n",
      "Idx:2800, Train_loss:1.282060146331787, Test loss:1.2672234773635864, test accuracy:0.60\n",
      "Idx:2900, Train_loss:0.7982829213142395, Test loss:0.8835391402244568, test accuracy:0.63\n",
      "Idx:3000, Train_loss:1.1369030475616455, Test loss:1.0297383069992065, test accuracy:0.63\n",
      "Idx:3100, Train_loss:1.0691964626312256, Test loss:0.9847720265388489, test accuracy:0.63\n"
     ]
    }
   ],
   "source": [
    "for idx, (img, label) in enumerate(train_dl):\n",
    "    model.train()\n",
    "    if idx > 40000:\n",
    "        break\n",
    "    optim.zero_grad()\n",
    "    \n",
    "    img = img.to(device)\n",
    "    label = label.to(device)\n",
    "    pred = model(img)\n",
    "    loss_val = loss_fn(pred, label)\n",
    "    loss_val.backward()\n",
    "    optim.step()\n",
    "    torch.save(model.state_dict(), './cifar10_tv_resnet101.pth')\n",
    "    if idx % 100 == 0:\n",
    "        model.eval()\n",
    "        correct = 0.0\n",
    "        with torch.no_grad():\n",
    "            for timg, tlabel in test_dl:\n",
    "                timg = timg.to(device)\n",
    "                tlabel = tlabel.to(device)\n",
    "                tout = model(timg)\n",
    "                loss_t = loss_fn(tout, tlabel)\n",
    "                correct += (tlabel == torch.argmax(tout, dim=1)).sum().item()\n",
    "            acc = correct/10000.0\n",
    "            #sched.step()\n",
    "            if acc >= best_acc:\n",
    "                print('saving model')\n",
    "                torch.save(model.state_dict(), './cifar10_tv_resnet101.pth')\n",
    "                best_acc = acc\n",
    "        print(f'Idx:{idx}, Train_loss:{loss_val.item()}, Test loss:{loss_t.item()}, test accuracy:{acc:.2f}')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
